{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration. Make sure the config file is present at ./config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "print('Workspace name: ' + ws.name,\n",
    "      'Azure region: ' + ws.location,\n",
    "      'Subscription id: ' + ws.subscription_id,\n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment named \"automl-experiment-heart-failure-classification\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure.\n",
    "\n",
    "The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the source directory for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the source directory would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the source_directory of the step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'automl-experiment-heart-failure-classification'\n",
    "project_folder = './classification-project'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach an AmlCompute cluster\n",
    "We will need to create a compute target for our AutoML run. We will use `vm_size = Standard_D2_V2` in our provisioning configuration and select `max_nodes` to be no greater than 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_compute_cluster_name = \"cpu-cluster\"\n",
    "\n",
    "# Verify that cluster doesn't exist already\n",
    "try:\n",
    "    aml_compute = ComputeTarget(workspace=ws, name=aml_compute_cluster_name)\n",
    "    print(\"Found existing cluster, use it.\")\n",
    "\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"Standard_D2_V2\",\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=4)\n",
    "    aml_compute = ComputeTarget.create(workspace=ws,\n",
    "                                       name=aml_compute_cluster_name,\n",
    "                                       provisioning_configuration=compute_config)\n",
    "    \n",
    "aml_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "\n",
    "for i, key in enumerate(compute_targets):\n",
    "    print(f\"{i+1}. Compute target\\n\\tname: {compute_targets[key].name}\\n\\tType: {compute_targets[key].type}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "This dataset contains the medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.\n",
    "\n",
    "The 12 clinical input features and the target feature are:\n",
    "\n",
    "- age: age of the patient (years)\n",
    "- anaemia: decrease of red blood cells or hemoglobin (boolean)\n",
    "- high blood pressure: if the patient has hypertension (boolean)\n",
    "- creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)\n",
    "- diabetes: if the patient has diabetes (boolean)\n",
    "- ejection fraction: percentage of blood leaving the heart at each contraction (percentage)\n",
    "- platelets: platelets in the blood (kiloplatelets/mL)\n",
    "- sex: woman or man (binary)\n",
    "- serum creatinine: level of serum creatinine in the blood (mg/dL)\n",
    "- serum sodium: level of serum sodium in the blood (mEq/L)\n",
    "- smoking: if the patient smokes or not (boolean)\n",
    "- time: follow-up period (days)\n",
    "- [target] death event: if the patient deceased during the follow-up period (boolean)\n",
    "\n",
    "The task we are concerned with is to predict if the patient deceased during the follow-up period. We will be using `DEATH_EVENT` column as the target and since this is a boolean variable, the task at hand is Binary Classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we write code to access the data that we will be using in this project.\n",
    "\n",
    "We will try to load the dataset from the Workspace. If it isn't found because it was deleted, it can be recreated with the link that has the CSV\n",
    "\n",
    "Make sure the `key` is the same name as the dataset that is uploaded. Also we provide a matching description. If it is hard to find or unknown, loop over the `ws.datasets.keys()` and `print()` them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found = False\n",
    "key = \"Health-Failure\"\n",
    "description_text = \"Health Failure dataset for mortality prediction\"\n",
    "\n",
    "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\"\n",
    "\n",
    "if key in ws.datasets.keys():\n",
    "    dataset = ws.datasets[key]\n",
    "    print(\"The Dataset was found!\")\n",
    "else:\n",
    "    # Create AML Dataset and register it into Workspace\n",
    "    dataset = Dataset.Tabular.from_delimited_files(dataset_url)\n",
    "    #Register Dataset in Workspace\n",
    "    dataset = dataset.register(workspace=ws,\n",
    "                               name=key,\n",
    "                               description=description_text)\n",
    "\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing datasets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Save training data to csv file\n",
    "train_df.to_csv(\"./train_data.csv\", index=False)\n",
    "\n",
    "# Read saved training data and create a dataset in Azure ML\n",
    "data_store = ws.get_default_datastore()\n",
    "data_store.upload(src_dir=\"./\", target_path=\"training_data\")\n",
    "train_ds = TabularDatasetFactory.from_delimited_files(path=[(data_store, 'training_data/train_data.csv')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the Dataset Result\n",
    "\n",
    "You can peek the result of a TabularDataset at any range using `skip(i)` and `take(j).to_pandas_dataframe()`. Doing so evaluates only `j` records for all the steps in the `TabularDataset`, which makes it fast even against large datasets.\n",
    "\n",
    "`TabularDataset` objects are composed of a list of transformation steps (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "train_ds.take(5).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "As mentioned above in the dataset section we are dealing with a binary classification. Therefore the argument `task` is set to `classification` and the since we are predicting `DEATH_EVENT` we need to set `label_column_name=\"DEATH_EVENT\"`\n",
    "\n",
    "To help manage child runs and when they can be performed, we recommend you create a dedicated cluster per experiment, and match the number of `max_concurrent_iterations` of your experiment to the number of nodes in the cluster. This way, you use all the nodes of the cluster at the same time with the number of concurrent child runs/iterations you want.\n",
    "\n",
    "Configure `max_concurrent_iterations` in your `AutoMLConfig` object. If it is not configured, then by default only one concurrent child run/iteration is allowed per experiment.\n",
    "\n",
    "Besides other arguments that are self-explanatory, to automate Feature engineering AzureML enables this through `featurization` that needs to be set to `True`. This way features that best characterize the patterns in the data are selected to create predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# AutoMl settings\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 30,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"primary_metric\": \"AUC_weighted\",\n",
    "    \"enable_early_stopping\": True,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "# AutoMl config\n",
    "automl_config = AutoMLConfig(compute_target=aml_compute,\n",
    "                             task=\"classification\",\n",
    "                             training_data=train_ds,\n",
    "                             label_column_name=\"DEATH_EVENT\",\n",
    "                             n_cross_validations=5,\n",
    "                             featurization=\"auto\",\n",
    "                             path=project_folder,\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             **automl_settings                             \n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Submit your experiment\n",
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve your best automl model.\n",
    "best_run, best_model = remote_run.get_output()\n",
    "best_run_metrics = best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_run.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "joblib.dump(best_model, filename=\"./best_automl_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model = Model.register(workspace=ws,\n",
    "                       model_name=\"heart_failure_pred_model\", \n",
    "                       model_path=\"./best_automl_model.joblib\",\n",
    "                       description=\"Best AutoML model\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = best_run.get_environment()\n",
    "\n",
    "inf_config = InferenceConfig(environment=env,\n",
    "                             entry_script='./score.py')\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1,\n",
    "                                                       memory_gb=1,\n",
    "                                                       auth_enabled=False,\n",
    "                                                       enable_app_insights=True)\n",
    "\n",
    "service = Model.deploy(workspace=ws, \n",
    "                       name=\"automl-service\",\n",
    "                       models=[model],\n",
    "                       inference_config=inf_config,\n",
    "                       deployment_config=deployment_config)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chech the state of the deployed service and get its URIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Service State: {service.state}\\n\")\n",
    "print(f\"Scoring URI: {service.scoring_uri}\\n\")\n",
    "print(f\"Swagger URI: {service.swagger_uri}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# URL for the web service\n",
    "scoring_uri = service.scoring_uri\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "#key = \"\"\n",
    "\n",
    "# 3 sets of data to score, so we get two results back\n",
    "data_df = test_df.sample(n=3)\n",
    "labels = data_df.pop('DEATH_EVENT')\n",
    "\n",
    "\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps({\"data\": data_df.to_dict(orient='records')})\n",
    "with open(\"input_data.json\", 'w') as _f:\n",
    "    _f.write(input_data)\n",
    "\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the content type\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# If authentication is enabled, set the authorization header\n",
    "#headers[\"Authorization\"] = f\"Bearer {key}\"\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predictions from Service: {resp.json()}\\n\")\n",
    "print(f\"Data Labels: {labels.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
